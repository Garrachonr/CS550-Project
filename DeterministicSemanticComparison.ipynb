{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPheCZSreVkn8G8a7abW6K+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7-zBcJcrZ9w5","executionInfo":{"status":"ok","timestamp":1712242912994,"user_tz":300,"elapsed":13716,"user":{"displayName":"Alfredo Garrachon Ruiz","userId":"16210802320104557047"}},"outputId":"9f28622e-d461-4722-92e8-f63b980f500a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install transformers torch"]},{"cell_type":"code","source":["from transformers import BertModel, BertTokenizer, AutoTokenizer, AutoModel\n","import torch\n","from scipy.spatial.distance import cosine\n","\n","#Model and tokenizer\n","model_name = 'mixedbread-ai/mxbai-embed-large-v1'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)\n","\n","#The two sets of answers\n","conjunto_a = [\"Agent_2 has been to Rome and Florence\",\n","              \"Agent_2 couldn't go to Venice\",\n","              \"Agent_1 wants to go to Florence\",\n","              \"Agent_1 has been to Tokio\",\n","              \"Agent_2 will need help from Agent_1 for the travel planning of Tokio\",\n","              \"Agent_1 thinks that Tokio looks like anime\"\n","              ]\n","conjunto_b = [\"Agent_2 loves to travel, especially now as a student\",\n","              \"Agent_2 recently visited Rome and Florence\",\n","              \"Agent_2 wanted to visit Venice but lacked time\",\n","              \"Agent_2 thinks Florence is the best city in Italy\",\n","              \"Agent_1 wants to visit Florence\",\n","              \"Agent_1 recently traveled to Tokyo\",\n","              \"Agent_2 is interested in visiting Tokyo\",\n","              \"Agent_1 found Tokyo very nice but big, hard to see all\",\n","              \"Tokyo's scenery is similar to anime, according to Agent_1\",\n","              \"Japanese culture is very different from European culture, noted by Agent_1\",\n","              \"Agent_2 plans to visit Tokyo next year and seeks Agent_1's help\",\n","              \"Agent_1 is willing to help Agent_2 with the trip to Tokyo, mentioning knowing how to go there\"\n","              ]\n","\n","#Function for obtaining the embeddings\n","def get_sentence_embedding(sentence, tokenizer, model):\n","    inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n","    outputs = model(**inputs)\n","    embeddings = outputs.last_hidden_state\n","    embeddings_mean = torch.mean(embeddings, dim=1)\n","    return embeddings_mean.squeeze().detach().numpy()\n","\n","\n","#Compute the semantic similitity on one direcction\n","def calculate_similarity_and_print(conjunto_a, conjunto_b, tokenizer, model):\n","    max_similarities = []\n","    for sent_a in conjunto_a:\n","        embedding_a = get_sentence_embedding(sent_a, tokenizer, model)\n","        max_similarity = -1\n","        selected_sent_b = \"\"\n","        for sent_b in conjunto_b:\n","            embedding_b = get_sentence_embedding(sent_b, tokenizer, model)\n","            similarity = 1 - cosine(embedding_a, embedding_b)\n","            if similarity > max_similarity:\n","                max_similarity = similarity\n","                selected_sent_b = sent_b\n","        max_similarities.append(max_similarity)\n","        #print(f\"Para la sentencia: '{sent_a}'\\nLa m√°s similar es: '{selected_sent_b}'\\nCon una similitud de: {max_similarity}\\n\")\n","\n","    mean_similarity = sum(max_similarities) / len(max_similarities)\n","    return mean_similarity\n","\n","#Compute the similarity for both direcctions\n","similarity_a_b = calculate_similarity_and_print(conjunto_a, conjunto_b, tokenizer, model)\n","print(f\"Similitud media de A a B: {similarity_a_b}\\n\")\n","similarity_b_a = calculate_similarity_and_print(conjunto_b, conjunto_a, tokenizer, model)\n","print(f\"Similitud media de B a A: {similarity_b_a}\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S0_7zDyxt_wb","executionInfo":{"status":"ok","timestamp":1712244161157,"user_tz":300,"elapsed":66104,"user":{"displayName":"Alfredo Garrachon Ruiz","userId":"16210802320104557047"}},"outputId":"dc12b64d-5198-4617-ee4b-6196392f521a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Similitud media de A a B: 0.9210421939690908\n","\n","Similitud media de B a A: 0.8690484861532847\n","\n"]}]}]}